knitr::opts_chunk$set(echo = TRUE)
library(lidR)
library(RCSF)
library(future)
library(profvis)
library(terra)
library(raster)
library(dplyr) # Install Rtools for compilation https://cran.r-project.org/bin/windows/Rtools/
library(purrr)
library(gdalUtilities)
library(ggplot2)
library(mapview)
library(mapedit)
#library(EBImage)
library(viridis)
library(RColorBrewer)
#library(treetop)
plan(multisession, workers = availableCores()/2)
# set number of threads lidR should use for functions that are parallelised
# HARDCODED here to half of available threads
set_lidr_threads(availableCores()/2)
#
# USER INPUT REQUIRED for input folder containing las file, output folder for results
#
in_dir = r"(R:\SET\Spatial Science\UAV\_data\Calperum\SASMDD0008\20240313\l2\level_1\20240313_SASMDD0008(1)\lidars\terra_las\)"
out_dir = r"(C:\Users\jcmontes\Documents\01_Projects-JC-Terraluma\TERN-Dronescape\Calperum_013-Lidar)"
# tmp folder for intermediate results (chunk outputs - delete on checking results)
tmp_dir = r"(C:\Users\jcmontes\Documents\01_Projects-JC-Terraluma\TERN-Dronescape\Calperum_013-Lidar)"
gnd_dir = paste(file.path(tmp_dir),"01_csf_gnd\\", sep="")
norm_dir = paste(file.path(tmp_dir), "02_ht_norm\\", sep="")
chm_dtm_dir = paste(file.path(tmp_dir), "03_chm_dtm\\", sep="")
metrics_dir = paste(file.path(tmp_dir), "04_metrics\\", sep="")
dir.create(out_dir)
dir.create(tmp_dir)
dir.create(gnd_dir)
dir.create(norm_dir)
dir.create(chm_dtm_dir)
dir.create(metrics_dir)
# Reference: https://github.com/r-lidar/lidRbook/
plot_transect <- function(las,
p1 = c(min(las@data$X), mean(las@data$Y)),
p2 = c(max(las@data$X), mean(las@data$Y)),
width = 5)
{
data_clip <- clip_transect(las, p1, p2, width, xz=TRUE) # set xz=TRUE to reorient point cloud to fit on XZ coords.
# ignore this - using xz true above.
# plot Northing along x axis if transect is along Y axis.
# len_y = max(data_clip@data$Y) - min(data_clip@data$Y)
# len_x = max(data_clip@data$X) - min(data_clip@data$X)
#
# #plot Y along X axis based on transect
# if(len_y > len_x) {
#   plot_x = data_clip@data$Y
# } else {
#   plot_x = data_clip@data$X
# }
p <- ggplot(data_clip@data, aes(X, Z, color = Z)) +
geom_point(size = 0.5) +
coord_equal() +
theme_minimal() +
scale_color_gradientn(colours = plasma(50))
return(p)
}
ctg <- readLAScatalog(in_dir)
# create lax files for spatial indexing if not done already
if(length(list.files(path = in_dir, pattern = "\\.lax$")) == 0)
{lidR:::catalog_laxindex(ctg)}
# quality check - las file or catalog?
# TEST THIS
# https://gis.stackexchange.com/questions/351821/capture-and-parse-output-of-lascheck-from-lidr
# las_check(las, FALSE)
# parse errors and warnings?
# USER to update parameters.
# set sloop_smooth to TRUE when terrain is steep
mycsf <- csf(sloop_smooth=FALSE, cloth_resolution = 0.5, iterations = 1000, class_threshold = 0.05)
# Set catalog options
opt_output_files(ctg) <- paste(gnd_dir, "csf_gnd_{ID}")
# Note: the warning "## Be careful, a chunk size smaller than 250 is likely to be irrelevant." likely does not account
# for high density drone point clouds.
# HARDCODED size. Other chunk sizes might be appropriate, for example, a smaller chunk size for a more dense point cloud
opt_chunk_size(ctg) <- 100 # 50?
opt_chunk_buffer(ctg) <- 10
opt_progress(ctg) <-FALSE
plot(ctg, chunk = TRUE)
ctg_gnd_classified <- classify_ground(ctg, mycsf, last_returns = FALSE)
lidR:::catalog_laxindex(ctg_gnd_classified)
# see that they are georeferenced right
plot(ctg_gnd_classified, mapview = TRUE, map.type = "Esri.WorldImagery")
# write ground classfied las
ctg<-readLAScatalog(gnd_dir)
las<-readLAS(ctg)
writeLAS(las,file.path(out_dir, "gnd_classified.laz"))
#thin point cloud
# enter required density in random()
#las<-decimate_points(las, random(165))
#writeLAS(las,file.path(gnd_dir, "gnd_classified_thinned.las"))
# Set catalog options
opt_output_files(ctg_gnd_classified) <- paste(chm_dtm_dir, "dtm_idw_{ID}", sep="")
opt_progress(ctg_gnd_classified) <-FALSE
plot(ctg_gnd_classified, chunk = TRUE)
# USER INPUT: update resolution. HARDCODED to 5 cm.
dtm_raster <- rasterize_terrain(ctg_gnd_classified, res=0.05, algorithm = knnidw(k = 10L, p = 2))
writeRaster(dtm_raster, file.path(out_dir, "dtm_raster_05.tif"), filetype="GTiff")
dtm_prod <- terrain(dtm_raster, v = c("slope", "aspect"), unit = "radians")
dtm_hillshade <- shade(slope = dtm_prod$slope, aspect = dtm_prod$aspect)
plot(dtm_hillshade, col =gray(0:30/30), legend = FALSE)
plot_dtm3d(dtm_raster)
# Set catalog options
opt_output_files(ctg_gnd_classified) <- paste(norm_dir, "ht_norm_{ID}", sep="")
opt_merge(ctg_gnd_classified) <- TRUE
plot(ctg_gnd_classified, chunk = TRUE)
ctg_norm <- normalize_height(ctg_gnd_classified, knnidw(k=10, p=2))
lidR:::catalog_laxindex(ctg_norm)
plot(ctg_norm["Max.Z"])
# Set catalog options
opt_merge(ctg_norm) <- TRUE
opt_output_files(ctg_norm) <-paste(chm_dtm_dir, "chm_{ID}", sep="")
opt_progress(ctg_norm)<-FALSE
plot(ctg_norm, chunk = TRUE)
# USER INPUT: update parameters. Resolution hardcoded to 5 cm.
chm_p2r_ctg = rasterize_canopy(ctg_norm, res=0.05, p2r(0.2))
plot(chm_p2r_ctg, col = viridis(10))
writeRaster(chm_p2r_ctg, file.path(out_dir, "chm_p2r20_05.tif"), filetype="GTiff")
canopyCover = function(z, rn){
first  = rn == 1L
zfirst = z[first]
num_first_rtns = length(zfirst)
first_above_thres = sum(zfirst > 1.4) # HARCODED height threshold 1.4 m
x = (first_above_thres/num_first_rtns) # output as fraction
return(x)
}
opt_output_files(ctg_norm) <-paste(chm_dtm_dir, "ccov_{ID}", sep="")
# USER INPUT: update resolution. HARDCODED to 1 m.
canopy_cover = pixel_metrics(ctg_norm, ~canopyCover(Z, rn=ReturnNumber), res = 1)
plot(canopy_cover, col = viridis(20))
writeRaster(canopy_cover, file.path(out_dir, "canopy_cover_1m.tif"), filetype="GTiff")
canopyDensity = function(z){
num_rtns = length(z)
num_above_thres = sum(z > 1.4)
x = (num_above_thres/num_rtns) # output as fraction
return(x)
}
opt_output_files(ctg_norm) <-paste(chm_dtm_dir, "cdns_{ID}", sep="")
# USER INPUT: update resolution. HARDCODED to 1 m.
canopy_dns = pixel_metrics(ctg_norm, ~canopyDensity(Z), res = 1)
plot(canopy_dns, col = viridis(20))
writeRaster(canopy_dns, file.path(out_dir, "canopy_dns_1m.tif"), filetype="GTiff")
# filter points
opt_filter(ctg_norm) <- "-drop_z_below 0"
opt_select(ctg_norm) <- "Z"
las <- readLAS(ctg_norm)
# Using default values, width = 5 m (HARDCODED), cross section along x-axis
plot_transect(las)
# Set point coordinates to plot cross section along Y-axis,
plot_transect(las, p1 = c(mean(las@data$X), min(las@data$Y)),
p2 = c(mean(las@data$X), max(las@data$Y)),
width = 5)
func_read_z <- function(chunk){
las <- readLAS(chunk)
if(is.empty(las)) return(NULL)
df = data.frame(Z = las$Z)
return(df)
}
# Reading z values from points, do not need a buffer.
# Set need_buffer false and buffer to 0. catlog_apply does not automatically crop buffer.
options <- list(automerge = TRUE, need_buffer=FALSE)
#HARDCODED threshold. Edit these options to plot last returns or other z thresholds
opt_filter(ctg_norm) <- "-drop_z_below 1.5"
opt_chunk_buffer(ctg_norm) = 0
df <- catalog_apply(ctg_norm, func_read_z, .options = options)
knitr::opts_chunk$set(echo = TRUE)
library(lidR)
library(RCSF)
library(future)
library(profvis)
library(terra)
library(raster)
library(dplyr) # Install Rtools for compilation https://cran.r-project.org/bin/windows/Rtools/
library(purrr)
library(gdalUtilities)
library(ggplot2)
library(mapview)
library(mapedit)
#library(EBImage)
library(viridis)
library(RColorBrewer)
#library(treetop)
plan(multisession, workers = availableCores()/2)
# set number of threads lidR should use for functions that are parallelised
# HARDCODED here to half of available threads
set_lidr_threads(availableCores()/2)
#
# USER INPUT REQUIRED for input folder containing las file, output folder for results
#
in_dir = r"(R:\SET\Spatial Science\UAV\_data\Calperum\SASMDD0013\20240310\l2\level_1\20240310_SASMDD0013\lidars\terra_las)"
out_dir = r"(C:\Users\jcmontes\Documents\01_Projects-JC-Terraluma\TERN-Dronescape\Calperum_013-Lidar)"
# tmp folder for intermediate results (chunk outputs - delete on checking results)
tmp_dir = r"(C:\Users\jcmontes\Documents\01_Projects-JC-Terraluma\TERN-Dronescape\Calperum_013-Lidar)"
gnd_dir = paste(file.path(tmp_dir),"01_csf_gnd\\", sep="")
norm_dir = paste(file.path(tmp_dir), "02_ht_norm\\", sep="")
chm_dtm_dir = paste(file.path(tmp_dir), "03_chm_dtm\\", sep="")
metrics_dir = paste(file.path(tmp_dir), "04_metrics\\", sep="")
dir.create(out_dir)
dir.create(tmp_dir)
dir.create(gnd_dir)
dir.create(norm_dir)
dir.create(chm_dtm_dir)
dir.create(metrics_dir)
# Reference: https://github.com/r-lidar/lidRbook/
plot_transect <- function(las,
p1 = c(min(las@data$X), mean(las@data$Y)),
p2 = c(max(las@data$X), mean(las@data$Y)),
width = 5)
{
data_clip <- clip_transect(las, p1, p2, width, xz=TRUE) # set xz=TRUE to reorient point cloud to fit on XZ coords.
# ignore this - using xz true above.
# plot Northing along x axis if transect is along Y axis.
# len_y = max(data_clip@data$Y) - min(data_clip@data$Y)
# len_x = max(data_clip@data$X) - min(data_clip@data$X)
#
# #plot Y along X axis based on transect
# if(len_y > len_x) {
#   plot_x = data_clip@data$Y
# } else {
#   plot_x = data_clip@data$X
# }
p <- ggplot(data_clip@data, aes(X, Z, color = Z)) +
geom_point(size = 0.5) +
coord_equal() +
theme_minimal() +
scale_color_gradientn(colours = plasma(50))
return(p)
}
ctg <- readLAScatalog(in_dir)
# create lax files for spatial indexing if not done already
if(length(list.files(path = in_dir, pattern = "\\.lax$")) == 0)
{lidR:::catalog_laxindex(ctg)}
# quality check - las file or catalog?
# TEST THIS
# https://gis.stackexchange.com/questions/351821/capture-and-parse-output-of-lascheck-from-lidr
# las_check(las, FALSE)
# parse errors and warnings?
# USER to update parameters.
# set sloop_smooth to TRUE when terrain is steep
mycsf <- csf(sloop_smooth=FALSE, cloth_resolution = 0.5, iterations = 1000, class_threshold = 0.05)
# Set catalog options
opt_output_files(ctg) <- paste(gnd_dir, "csf_gnd_{ID}")
# Note: the warning "## Be careful, a chunk size smaller than 250 is likely to be irrelevant." likely does not account
# for high density drone point clouds.
# HARDCODED size. Other chunk sizes might be appropriate, for example, a smaller chunk size for a more dense point cloud
opt_chunk_size(ctg) <- 100 # 50?
opt_chunk_buffer(ctg) <- 10
opt_progress(ctg) <-FALSE
plot(ctg, chunk = TRUE)
ctg_gnd_classified <- classify_ground(ctg, mycsf, last_returns = FALSE)
lidR:::catalog_laxindex(ctg_gnd_classified)
# see that they are georeferenced right
plot(ctg_gnd_classified, mapview = TRUE, map.type = "Esri.WorldImagery")
# write ground classfied las
ctg<-readLAScatalog(gnd_dir)
las<-readLAS(ctg)
writeLAS(las,file.path(out_dir, "gnd_classified.laz"))
#thin point cloud
# enter required density in random()
#las<-decimate_points(las, random(165))
#writeLAS(las,file.path(gnd_dir, "gnd_classified_thinned.las"))
# Set catalog options
opt_output_files(ctg_gnd_classified) <- paste(chm_dtm_dir, "dtm_idw_{ID}", sep="")
opt_progress(ctg_gnd_classified) <-FALSE
plot(ctg_gnd_classified, chunk = TRUE)
# USER INPUT: update resolution. HARDCODED to 5 cm.
dtm_raster <- rasterize_terrain(ctg_gnd_classified, res=0.05, algorithm = knnidw(k = 10L, p = 2))
knitr::opts_chunk$set(echo = TRUE)
library(lidR)
library(RCSF)
library(future)
library(profvis)
library(terra)
library(raster)
library(dplyr) # Install Rtools for compilation https://cran.r-project.org/bin/windows/Rtools/
library(purrr)
library(gdalUtilities)
library(ggplot2)
library(mapview)
library(mapedit)
#library(EBImage)
library(viridis)
library(RColorBrewer)
#library(treetop)
plan(multisession, workers = availableCores()/2)
# set number of threads lidR should use for functions that are parallelised
# HARDCODED here to half of available threads
set_lidr_threads(availableCores()/2)
#
# USER INPUT REQUIRED for input folder containing las file, output folder for results
#
in_dir = r"(R:\SET\Spatial Science\UAV\_data\Calperum\SASMDD0013\20240310\l2\level_1\20240310_SASMDD0013\lidars\terra_las)"
out_dir = r"(C:\Users\jcmontes\Documents\01_Projects-JC-Terraluma\TERN-Dronescape\Calperum_013-Lidar)"
# tmp folder for intermediate results (chunk outputs - delete on checking results)
tmp_dir = r"(C:\Users\jcmontes\Documents\01_Projects-JC-Terraluma\TERN-Dronescape\Calperum_013-Lidar)"
gnd_dir = paste(file.path(tmp_dir),"01_csf_gnd\\", sep="")
norm_dir = paste(file.path(tmp_dir), "02_ht_norm\\", sep="")
chm_dtm_dir = paste(file.path(tmp_dir), "03_chm_dtm\\", sep="")
metrics_dir = paste(file.path(tmp_dir), "04_metrics\\", sep="")
dir.create(out_dir)
dir.create(tmp_dir)
dir.create(gnd_dir)
dir.create(norm_dir)
dir.create(chm_dtm_dir)
dir.create(metrics_dir)
# Reference: https://github.com/r-lidar/lidRbook/
plot_transect <- function(las,
p1 = c(min(las@data$X), mean(las@data$Y)),
p2 = c(max(las@data$X), mean(las@data$Y)),
width = 5)
{
data_clip <- clip_transect(las, p1, p2, width, xz=TRUE) # set xz=TRUE to reorient point cloud to fit on XZ coords.
# ignore this - using xz true above.
# plot Northing along x axis if transect is along Y axis.
# len_y = max(data_clip@data$Y) - min(data_clip@data$Y)
# len_x = max(data_clip@data$X) - min(data_clip@data$X)
#
# #plot Y along X axis based on transect
# if(len_y > len_x) {
#   plot_x = data_clip@data$Y
# } else {
#   plot_x = data_clip@data$X
# }
p <- ggplot(data_clip@data, aes(X, Z, color = Z)) +
geom_point(size = 0.5) +
coord_equal() +
theme_minimal() +
scale_color_gradientn(colours = plasma(50))
return(p)
}
ctg <- readLAScatalog(in_dir)
# create lax files for spatial indexing if not done already
if(length(list.files(path = in_dir, pattern = "\\.lax$")) == 0)
{lidR:::catalog_laxindex(ctg)}
# quality check - las file or catalog?
# TEST THIS
# https://gis.stackexchange.com/questions/351821/capture-and-parse-output-of-lascheck-from-lidr
# las_check(las, FALSE)
# parse errors and warnings?
# USER to update parameters.
# set sloop_smooth to TRUE when terrain is steep
mycsf <- csf(sloop_smooth=FALSE, cloth_resolution = 0.5, iterations = 1000, class_threshold = 0.05)
# Set catalog options
opt_output_files(ctg) <- paste(gnd_dir, "csf_gnd_{ID}")
# Note: the warning "## Be careful, a chunk size smaller than 250 is likely to be irrelevant." likely does not account
# for high density drone point clouds.
# HARDCODED size. Other chunk sizes might be appropriate, for example, a smaller chunk size for a more dense point cloud
opt_chunk_size(ctg) <- 100 # 50?
opt_chunk_buffer(ctg) <- 10
opt_progress(ctg) <-FALSE
plot(ctg, chunk = TRUE)
ctg_gnd_classified <- classify_ground(ctg, mycsf, last_returns = FALSE)
lidR:::catalog_laxindex(ctg_gnd_classified)
# see that they are georeferenced right
plot(ctg_gnd_classified, mapview = TRUE, map.type = "Esri.WorldImagery")
# write ground classfied las
ctg<-readLAScatalog(gnd_dir)
las<-readLAS(ctg)
writeLAS(las,file.path(out_dir, "gnd_classified.laz"))
#thin point cloud
# enter required density in random()
#las<-decimate_points(las, random(165))
#writeLAS(las,file.path(gnd_dir, "gnd_classified_thinned.las"))
# Set catalog options
opt_output_files(ctg_gnd_classified) <- paste(chm_dtm_dir, "dtm_idw_{ID}", sep="")
opt_progress(ctg_gnd_classified) <-FALSE
plot(ctg_gnd_classified, chunk = TRUE)
# USER INPUT: update resolution. HARDCODED to 5 cm.
dtm_raster <- rasterize_terrain(ctg_gnd_classified, res=0.05, algorithm = knnidw(k = 10L, p = 2))
writeRaster(dtm_raster, file.path(out_dir, "dtm_raster_05.tif"), filetype="GTiff")
dtm_prod <- terrain(dtm_raster, v = c("slope", "aspect"), unit = "radians")
dtm_hillshade <- shade(slope = dtm_prod$slope, aspect = dtm_prod$aspect)
plot(dtm_hillshade, col =gray(0:30/30), legend = FALSE)
plot_dtm3d(dtm_raster)
# Set catalog options
opt_output_files(ctg_gnd_classified) <- paste(norm_dir, "ht_norm_{ID}", sep="")
opt_merge(ctg_gnd_classified) <- TRUE
plot(ctg_gnd_classified, chunk = TRUE)
ctg_norm <- normalize_height(ctg_gnd_classified, knnidw(k=10, p=2))
lidR:::catalog_laxindex(ctg_norm)
plot(ctg_norm["Max.Z"])
# Set catalog options
opt_merge(ctg_norm) <- TRUE
opt_output_files(ctg_norm) <-paste(chm_dtm_dir, "chm_{ID}", sep="")
opt_progress(ctg_norm)<-FALSE
plot(ctg_norm, chunk = TRUE)
# USER INPUT: update parameters. Resolution hardcoded to 5 cm.
chm_p2r_ctg = rasterize_canopy(ctg_norm, res=0.05, p2r(0.2))
plot(chm_p2r_ctg, col = viridis(10))
writeRaster(chm_p2r_ctg, file.path(out_dir, "chm_p2r20_05.tif"), filetype="GTiff")
canopyCover = function(z, rn){
first  = rn == 1L
zfirst = z[first]
num_first_rtns = length(zfirst)
first_above_thres = sum(zfirst > 1.4) # HARCODED height threshold 1.4 m
x = (first_above_thres/num_first_rtns) # output as fraction
return(x)
}
opt_output_files(ctg_norm) <-paste(chm_dtm_dir, "ccov_{ID}", sep="")
# USER INPUT: update resolution. HARDCODED to 1 m.
canopy_cover = pixel_metrics(ctg_norm, ~canopyCover(Z, rn=ReturnNumber), res = 1)
plot(canopy_cover, col = viridis(20))
writeRaster(canopy_cover, file.path(out_dir, "canopy_cover_1m.tif"), filetype="GTiff")
canopyDensity = function(z){
num_rtns = length(z)
num_above_thres = sum(z > 1.4)
x = (num_above_thres/num_rtns) # output as fraction
return(x)
}
opt_output_files(ctg_norm) <-paste(chm_dtm_dir, "cdns_{ID}", sep="")
# USER INPUT: update resolution. HARDCODED to 1 m.
canopy_dns = pixel_metrics(ctg_norm, ~canopyDensity(Z), res = 1)
plot(canopy_dns, col = viridis(20))
writeRaster(canopy_dns, file.path(out_dir, "canopy_dns_1m.tif"), filetype="GTiff")
# filter points
opt_filter(ctg_norm) <- "-drop_z_below 0"
opt_select(ctg_norm) <- "Z"
las <- readLAS(ctg_norm)
# Using default values, width = 5 m (HARDCODED), cross section along x-axis
plot_transect(las)
